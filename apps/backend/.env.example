# === DeepSeek LLM ===
# Required for AI-powered scanner crew
DEEPSEEK_API_KEY=your-deepseek-api-key-here

# === Phoenix Observability ===
# Set to true to auto-start local Phoenix UI at localhost:6006
PHOENIX_AUTO_START=true

# For Phoenix Cloud (leave empty to use local):
# PHOENIX_API_KEY=your-phoenix-cloud-api-key
# PHOENIX_COLLECTOR_ENDPOINT=https://app.phoenix.arize.com

# === Frontend CORS ===
FRONTEND_URL=http://localhost:3000

# === Analytics Query Security ===
# SECURITY CRITICAL: When true, REJECT queries that don't match pre-defined templates
# instead of falling back to LLM-generated SQL. This prevents SQL injection attacks
# via malicious natural language prompts (~10% of queries fall through to LLM).
# Set to "false" ONLY in development environments with trusted users.
ANALYTICS_TEMPLATES_ONLY=true

# Enable template routing for analytics queries (default: true)
# When false, ALL queries go to LLM (not recommended for production)
ANALYTICS_USE_TEMPLATES=true

# === Comparative Analysis Feature Flags ===
# Enable materialized view for rankings (set to false for legacy N+1 queries)
USE_MATERIALIZED_RANKINGS=true

# How often to refresh the rankings view (in seconds, default 15 minutes)
RANKINGS_REFRESH_INTERVAL=900

# In-memory cache TTL for rankings queries (in seconds)
RANKINGS_CACHE_TTL=30

# === Policy RAG Search Feature Flags ===
# Controls the search strategy for policy queries (keyword vs semantic)

# Primary search method: "keyword" | "semantic" | "hybrid"
# - keyword: Fast full-text search (<100ms P95), best for simple queries
# - semantic: Vector similarity search (~350ms P95), best for complex/multi-concept queries
# - hybrid: Combines both using Reciprocal Rank Fusion (RRF)
POLICY_PRIMARY_SEARCH=keyword

# Enable semantic search fallback when keyword returns insufficient results
POLICY_SEMANTIC_FALLBACK=true

# Minimum keyword results before fallback triggers
KEYWORD_MIN_RESULTS=2

# Query complexity threshold (0.0-1.0) for automatic routing to semantic search
# Simple queries (<=2 words, exact phrases) score low, complex queries score high
COMPLEXITY_SEMANTIC_THRESHOLD=0.5

# Log slow searches exceeding this threshold (milliseconds)
SEARCH_LATENCY_LOG_THRESHOLD_MS=100

# === Tiered Document Validation (Vision Tools) ===
# Cost optimization: Routes documents through rule-based checks first, then
# DeepSeek Vision ($0.01), then GPT-4V ($0.08) only when needed.
# Target: Reduce average cost from $0.08 to $0.02 per document (75% savings)

# Enable Tier 1 rule-based validation (file format, size, magic bytes)
# Set to "false" to skip rule-based checks and go directly to AI vision
TIER1_VALIDATION_ENABLED=true

# Provider for Tier 2 vision analysis: "deepseek" | "openai"
# DeepSeek is 8x cheaper than OpenAI GPT-4V
TIER2_PROVIDER=deepseek

# Confidence thresholds for tier routing (0.0 - 1.0)
# Documents scoring >= TIER1 are approved by rule-based validation
# Documents scoring >= TIER2 are sent to DeepSeek Vision
# Documents scoring < TIER2 are sent to GPT-4V (most expensive)
VISION_CONFIDENCE_TIER1=0.85
VISION_CONFIDENCE_TIER2=0.60

# Master switch to enable/disable the entire tiered validation system
# Set to "false" to use GPT-4V directly for all documents (legacy behavior)
TIERED_VALIDATION_ENABLED=true

# OpenAI API key for GPT-4V (Tier 3 fallback)
# Required if TIERED_VALIDATION_ENABLED=false or for Tier 3 fallback
# OPENAI_API_KEY=your-openai-api-key-here

# Note: This backend loads environment variables from the monorepo root .env.local file
# Copy this file to the root directory as .env.local and fill in your actual values
